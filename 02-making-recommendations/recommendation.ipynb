{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 4.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'You, Me and Dupree': 2.5\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5\n",
    "    },\n",
    "    'Toby': {\n",
    "        'Snakes on a Plane': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 1.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Lisa Rose', 'Gene Seymour', 'Michael Phillips', 'Claudia Puig', 'Mick LaSalle', 'Jack Matthews', 'Toby'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the critics.\n",
    "critics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lady in the Water': 2.5,\n",
       " 'Snakes on a Plane': 3.5,\n",
       " 'Just My Luck': 3.0,\n",
       " 'Superman Returns': 3.5,\n",
       " 'You, Me and Dupree': 2.5,\n",
       " 'The Night Listener': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the ratings by Lisa Rose.\n",
    "critics['Lisa Rose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1622776601683795"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the euclidean distance.\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(pow(5-4,2) + pow(4-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1622776601683795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using numpy.\n",
    "import numpy as np\n",
    "from numpy.linalg import norm as euclidean\n",
    "\n",
    "euclidean(np.array([5,4]) - np.array([4,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2402530733520421"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The smaller the distance between the two points, the more similar they are.\n",
    "# To convert it into score (the higher the score, the more similar the users),\n",
    "# we just need to take the inverse of it. We add 1 to the denominator to avoid\n",
    "# zero-division.\n",
    "# A value of 1 means that two users have identical preference.\n",
    "1 / (1 + sqrt(pow(5-4,2) + pow(4-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "\n",
    "def intersect(a, b):\n",
    "    \"\"\"Takes two dict, a and b, and returns the keys that exists in both dict.\"\"\"\n",
    "    return a.keys() & b.keys()\n",
    "\n",
    "def similarity_euclidean(prefs, person1, person2):\n",
    "    # Find the common similarity between both users.\n",
    "    similarity_set = intersect(prefs[person1], prefs[person2])\n",
    "    \n",
    "    # If they have no ratings in common, return 0.\n",
    "    if len(similarity_set) == 0: return 0\n",
    "    \n",
    "    square_distance = lambda item: pow(prefs[person1][item] - prefs[person2][item], 2)\n",
    "    \n",
    "    sum_of_squares = sum([square_distance(item) for item in similarity_set])\n",
    "    return 1 / (1 + sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14814814814814814"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The similarity between two users can then be calculated.\n",
    "similarity_euclidean(critics, 'Lisa Rose', 'Gene Seymour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestSimilarityDistance(unittest.TestCase):\n",
    "    def test_intersect_one_key(self):\n",
    "        a = {'a': 1}\n",
    "        b = {'a': 2, 'b': 3}\n",
    "        want = {'a'}\n",
    "        got = intersect(a, b)\n",
    "        self.assertEqual(want, got)\n",
    "\n",
    "    def test_intersect_no_keys(self):\n",
    "        a = {'a': 1}\n",
    "        b = {'b': 2}\n",
    "        want = set()\n",
    "        got = intersect(a, b)\n",
    "        self.assertEqual(want, got)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['hello world'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def similarity_pearson(prefs, person1, person2):\n",
    "    # Only compute ratings for similar preferences.\n",
    "    similarity_set = intersect(prefs[person1], prefs[person2])    \n",
    "    \n",
    "    # If there are no ratings in common, return 0.\n",
    "    if len(similarity_set) == 0: return 0\n",
    "    \n",
    "    # Get the ratings for both users.\n",
    "    rate1 = []\n",
    "    rate2 = []\n",
    "    for item in similarity_set:\n",
    "        rate1.append(prefs[person1][item])\n",
    "        rate2.append(prefs[person2][item])\n",
    "    \n",
    "    # Compute the pearson score.\n",
    "    return pearsonr(rate1, rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39605901719066977"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_score, p_value = similarity_pearson(critics, 'Lisa Rose', 'Gene Seymour')\n",
    "pearson_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw way of calculating pearson score, in case we need to implement it in another language without using any libraries.\n",
    "def _pearson(prefs, person1, person2):\n",
    "    # Get the list of mutually rated items.\n",
    "    si = {}\n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item] = 1\n",
    "    \n",
    "    # Find the number of elements.\n",
    "    n = len(si)\n",
    "    \n",
    "    # If there are no ratings in common, return 0.\n",
    "    if n == 0: return 0\n",
    "    \n",
    "    rate1 = [prefs[person1][it] for it in si]\n",
    "    rate2 = [prefs[person2][it] for it in si]\n",
    "    \n",
    "    # Add up all preferences.\n",
    "    sum1 = sum(rate1)\n",
    "    sum2 = sum(rate2)\n",
    "    \n",
    "    # Sum of all squares.\n",
    "    sum1_square = sum([i * i for i in rate1])\n",
    "    sum2_square = sum([i * i for i in rate2])\n",
    "    \n",
    "    # Sum of product.\n",
    "    sum_product = sum([a * b for (a, b) in zip(rate1, rate2)])\n",
    "    \n",
    "    # Pearson score.\n",
    "    num = sum_product - (sum1 * sum2/n)\n",
    "    den = sqrt((sum1_square - sum1 * sum1/n) * (sum2_square - sum2 * sum2/n))\n",
    "    if den == 0: return 0\n",
    "    return num /den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39605901719066977"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pearson(critics, 'Lisa Rose', 'Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking the critics\n",
    "\n",
    "To rank the critics relative to a user, we just need to calculate the similarity score of other users\n",
    "and return the results in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_matches(prefs, person, n = 5, similarity = similarity_pearson):\n",
    "    scores = [(similarity(prefs, person, other), other) for other in prefs if other != person]\n",
    "    scores.sort(reverse=True)\n",
    "    return scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.9912407071619302, 0.08432321632194426), 'Lisa Rose'),\n",
       " ((0.9244734516419049, 0.24901011701138978), 'Mick LaSalle'),\n",
       " ((0.8934051474415642, 0.2966188313316005), 'Claudia Puig'),\n",
       " ((0.6628489803598703, 0.5386942679789539), 'Jack Matthews'),\n",
       " ((0.3812464258315117, 0.7509898829886107), 'Gene Seymour')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_matches(critics, 'Toby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3076923076923077, 'Mick LaSalle'),\n",
       " (0.2857142857142857, 'Michael Phillips'),\n",
       " (0.23529411764705882, 'Claudia Puig')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_matches(critics, 'Toby', n = 3, similarity = similarity_euclidean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending items.\n",
    "\n",
    "For each user (excluding yourself), find the similarity score first. Then, for each items they rate, multiply it with the similarity score. Take the sum of the scores divided by the total similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(prefs, person, similarity=similarity_pearson):\n",
    "    totals = {}\n",
    "    sim_sums = {}\n",
    "    for other in prefs:\n",
    "        # Don't compare to yourself.\n",
    "        if other == person: continue\n",
    "        sim, _ = similarity(prefs, person, other)\n",
    "        \n",
    "        # Ignore scores of zero or lower.\n",
    "        if sim <= 0: continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movie I haven't seen yet.\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * score.\n",
    "                totals.setdefault(item, 0)\n",
    "                totals[item] += prefs[other][item] * sim\n",
    "                \n",
    "                # Sum of similarity.\n",
    "                sim_sums.setdefault(item, 0)\n",
    "                sim_sums[item] += sim\n",
    "\n",
    "    # Create the normalized list.\n",
    "    rankings = [(total/sim_sums[item], item) for item, total in totals.items()]\n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Snakes on a Plane', 'Superman Returns', 'You, Me and Dupree'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What Toby has watched and rated.\n",
    "critics['Toby'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.347789526713101, 'The Night Listener'),\n",
       " (2.832549918264162, 'Lady in the Water'),\n",
       " (2.5309807037655645, 'Just My Luck')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is recommended for Toby.\n",
    "get_recommendations(critics, 'Toby')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
