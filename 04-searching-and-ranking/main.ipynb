{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://resources.oreilly.com/examples/9780596529321/tree/master\n",
    "\n",
    "class crawler:\n",
    "    # Initialize the crawler with the name of database.\n",
    "    def __init__(self, db):\n",
    "        pass\n",
    "    \n",
    "    def __del__(self):\n",
    "        pass\n",
    "\n",
    "    def commit(self):\n",
    "        pass\n",
    "    \n",
    "    # Auxialliary function for getting an entry id and adding it if it is not present.\n",
    "    def get_entry_id(self, table, field, value, create_new = True):\n",
    "        return None\n",
    "    \n",
    "    # Index an individual page.\n",
    "    def add_to_index(self, url, soup):\n",
    "        print(f'indexing {url}')\n",
    "    \n",
    "    # Extract the text from the HTML page (no tags).\n",
    "    def get_text_only(self, soup):\n",
    "        return None\n",
    "    \n",
    "    # Separate the words by non-whitespace character.\n",
    "    def separate_words(self, text):\n",
    "        return None\n",
    "    \n",
    "    # Return true if this url is already indexed.\n",
    "    def is_indexed(self, url):\n",
    "        return False\n",
    "    \n",
    "    # Add a link between pages.\n",
    "    def add_link_ref(self, url_from, url_to, link_text):\n",
    "        pass\n",
    "\n",
    "    # Starting with a list of pages, do a breadth first search to the given depth,\n",
    "    # indexing pages as we go.\n",
    "    def crawl(self, pages, depth = 2):\n",
    "        pass\n",
    "    \n",
    "    # Create the database tables.\n",
    "    def create_index_tables(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextanhongpin/Library/Python/3.7/lib/python/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Programming language - Wikipedia</title>\\n<script>document.documentElement.className=document.documentElement.className.replace(/(^|\\\\s)client-nojs(\\\\s|$)/,\"$1client-js$2\");RLCONF={\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":!1,\"wgNamespaceNumber\":0,\"wgPageName\":\"Programming_language\",\"wgTitle\":\"Programming language\",\"wgCurRevisionId\":900725449,\"wgRevisionId\":900725449,\"wgArticleId\":23015')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://en.wikipedia.org/wiki/Programming_language'\n",
    "# 'http://kiwitobes.com/wiki/Programming_language.html'\n",
    "r = http.request('GET', url)\n",
    "r.status, r.data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import sqlite3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "url = 'https://en.wikipedia.org/wiki/Programming_language'\n",
    "# pip3 install beautifulsoup4\n",
    "\n",
    "class Crawler:\n",
    "    # Initialize the crawler with the name of database.\n",
    "    def __init__(self, db):\n",
    "        self.conn = sqlite3.connect(db)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.conn.close()\n",
    "\n",
    "    def commit(self):\n",
    "        self.conn.commit()\n",
    "    \n",
    "    # Auxialliary function for getting an entry id and adding it if it is not present.\n",
    "    def get_entry_id(self, table, field, value, create_new = True):\n",
    "        c = self.conn.cursor()\n",
    "        res = c.execute(f'select rowid from {table} where {field} = ?', (value,)).fetchone()\n",
    "        if res == None:\n",
    "            stmt = f'insert into {table} ({field}) values (?)'\n",
    "            r = self.conn.execute(stmt, (value,))\n",
    "            return r.lastrowid\n",
    "        else:\n",
    "            return res[0]\n",
    "    \n",
    "    # Index an individual page.\n",
    "    def add_to_index(self, url, soup):\n",
    "        if self.is_indexed(url): return\n",
    "        print(f'indexing {url}')\n",
    "        \n",
    "        # Get the individual words.\n",
    "        text = self.get_text_only(soup)\n",
    "        words = self.separate_words(text)\n",
    "        \n",
    "        # Get the URL id.\n",
    "        url_id = self.get_entry_id('urllist', 'url', url)\n",
    "        \n",
    "        # Link each word to this url.\n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in stopwords: continue\n",
    "            word_id = self.get_entry_id('wordlist', 'word', word)\n",
    "            self.conn.execute('insert into wordlocation(url_id, word_id, location) values (?, ?, ?)', (url_id, word_id, i))\n",
    "    \n",
    "    # Extract the text from the HTML page (no tags).\n",
    "    def get_text_only(self, soup):\n",
    "        return soup.get_text()\n",
    "#         v = soup.string\n",
    "#         if v == None:\n",
    "#             c = soup.contents\n",
    "#             result_text = ''\n",
    "#             for t in c:\n",
    "#                 subtext = self.get_text_only(t)\n",
    "#                 result_text += subtext + '\\n'\n",
    "#             return result_text\n",
    "#         else:\n",
    "#             return v.strip()\n",
    "    \n",
    "    # Separate the words by non-whitespace character.\n",
    "    def separate_words(self, text):\n",
    "        # splitter = re.compile('\\\\W*')\n",
    "        splitter=re.compile('\\W+')\n",
    "        return [s.lower() for s in splitter.split(text) if s != '']\n",
    "    \n",
    "    # Return true if this url is already indexed.\n",
    "    def is_indexed(self, url):\n",
    "        cur = self.conn.cursor()\n",
    "        res = cur.execute('select url from urllist where url = ?', (url,)).fetchone()\n",
    "        if res != None:\n",
    "            # Check if it has actually been crawled.\n",
    "            cur = self.conn.cursor()\n",
    "            c = cur.execute('select * from wordlocation where url_id = ?', (res[0],))\n",
    "            if c != None:\n",
    "                res = c.fetchone()\n",
    "                if res != None: return True\n",
    "        return False\n",
    "    \n",
    "    # Add a link between pages.\n",
    "    def add_link_ref(self, url_from, url_to, link_text):\n",
    "        words = self.separate_words(link_text)\n",
    "        from_id = self.get_entry_id('urllist', 'url', url_from)\n",
    "        to_id = self.get_entry_id('urllist', 'url', url_to)\n",
    "        if from_id == to_id: return\n",
    "        c = self.conn.cursor()\n",
    "        res = c.execute('insert into link(from_id,to_id) values (?, ?)', (from_id, to_id))\n",
    "        link_id = res.lastrowid\n",
    "        for word in words:\n",
    "            if word in stopwords: continue\n",
    "            word_id = self.get_entry_id('wordlist', 'word', word)\n",
    "            self.conn.execute('insert into linkwords(link_id, word_id) values (?, ?)', (link_id, word_id))\n",
    "    # Starting with a list of pages, do a breadth first search to the given depth,\n",
    "    # indexing pages as we go.\n",
    "    def crawl(self, pages, depth = 2):\n",
    "        for i in range(depth):\n",
    "            new_pages = set()\n",
    "            for page in pages:\n",
    "                try:\n",
    "                    r = http.request('GET', page)\n",
    "                    # r.status, r.data \n",
    "                    print(f'loaded page {page} {r.status}')\n",
    "                except:\n",
    "                    print(f'could not open page {page}')\n",
    "                    continue\n",
    "                soup = BeautifulSoup(r.data, 'html.parser')\n",
    "                self.add_to_index(page, soup)\n",
    "                \n",
    "                links = soup.find_all('a')\n",
    "                for link in links:\n",
    "                    url = urljoin(page, link.get('href'))\n",
    "                    # if url.find(\"'\") != -1: continue\n",
    "                    url = url.split('#')[0] # Remove location portion.\n",
    "                    if url[0:5] == 'https' and not self.is_indexed(url):\n",
    "                        print(f'indexing {url}')\n",
    "                        new_pages.add(url)\n",
    "                    link_text = self.get_text_only(link)\n",
    "                    self.add_link_ref(page, url, link_text)\n",
    "                self.commit()\n",
    "            pages = new_pages\n",
    "                \n",
    "    # Create the database tables.\n",
    "    def create_index_tables(self):\n",
    "        self.conn.execute('create table if not exists urllist(url)')\n",
    "        self.conn.execute('create table if not exists wordlist(word)')\n",
    "        self.conn.execute('create table if not exists wordlocation(url_id, word_id, location)')\n",
    "        self.conn.execute('create table if not exists link(from_id integer, to_id integer)')\n",
    "        self.conn.execute('create table if not exists linkwords(word_id, link_id)')\n",
    "        self.conn.execute('create index if not exists wordidx on wordlist(word)')\n",
    "        self.conn.execute('create index if not exists urlidx on urllist(url)')\n",
    "        self.conn.execute('create index if not exists wordurlidx on wordlocation(word_id)')\n",
    "        self.conn.execute('create index if not exists urltoidx on link(to_id)')\n",
    "        self.conn.execute('create index if not exists urlfromidx on link(from_id)')\n",
    "        self.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = Crawler('searchindex.db')\n",
    "crawler.create_index_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%skip` not found.\n"
     ]
    }
   ],
   "source": [
    "%skip\n",
    "crawler.crawl([\n",
    "    'https://en.wikipedia.org/wiki/Programming_language',\n",
    "    'https://en.wikipedia.org/wiki/Categorical_list_of_programming_languages.html',\n",
    "    'https://en.wikipedia.org/wiki/Functional_programming'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,),\n",
       " (25,),\n",
       " (118,),\n",
       " (121,),\n",
       " (461,),\n",
       " (489,),\n",
       " (497,),\n",
       " (508,),\n",
       " (512,),\n",
       " (515,),\n",
       " (528,),\n",
       " (580,),\n",
       " (587,),\n",
       " (606,),\n",
       " (622,),\n",
       " (745,),\n",
       " (757,),\n",
       " (770,),\n",
       " (776,),\n",
       " (811,),\n",
       " (823,),\n",
       " (835,),\n",
       " (840,),\n",
       " (847,),\n",
       " (857,),\n",
       " (866,),\n",
       " (880,),\n",
       " (926,),\n",
       " (941,),\n",
       " (946,),\n",
       " (988,),\n",
       " (1003,),\n",
       " (1032,),\n",
       " (1037,),\n",
       " (1041,),\n",
       " (1063,),\n",
       " (1078,),\n",
       " (1087,),\n",
       " (1101,),\n",
       " (1175,),\n",
       " (1184,),\n",
       " (1213,),\n",
       " (1217,),\n",
       " (1225,),\n",
       " (1293,),\n",
       " (1317,),\n",
       " (1399,),\n",
       " (1425,),\n",
       " (1456,),\n",
       " (1498,),\n",
       " (1501,),\n",
       " (1542,),\n",
       " (1545,),\n",
       " (1551,),\n",
       " (1574,),\n",
       " (1584,),\n",
       " (1599,),\n",
       " (1612,),\n",
       " (1626,),\n",
       " (1632,),\n",
       " (1646,),\n",
       " (1648,),\n",
       " (1667,),\n",
       " (1676,),\n",
       " (1681,),\n",
       " (1695,),\n",
       " (1702,),\n",
       " (1722,),\n",
       " (1748,),\n",
       " (1774,),\n",
       " (1803,),\n",
       " (1836,),\n",
       " (1838,),\n",
       " (1862,),\n",
       " (1866,),\n",
       " (1880,),\n",
       " (1883,),\n",
       " (1899,),\n",
       " (1930,),\n",
       " (1950,),\n",
       " (1956,),\n",
       " (1973,),\n",
       " (2012,),\n",
       " (2233,),\n",
       " (2240,),\n",
       " (2396,),\n",
       " (2417,),\n",
       " (2478,),\n",
       " (2492,),\n",
       " (2512,),\n",
       " (2624,),\n",
       " (2854,),\n",
       " (3030,),\n",
       " (3115,),\n",
       " (3246,),\n",
       " (3281,),\n",
       " (3315,),\n",
       " (3318,),\n",
       " (3337,),\n",
       " (3349,),\n",
       " (3415,),\n",
       " (3426,),\n",
       " (3434,),\n",
       " (3468,),\n",
       " (3475,),\n",
       " (3499,),\n",
       " (3524,),\n",
       " (3534,),\n",
       " (3538,),\n",
       " (3556,),\n",
       " (3641,),\n",
       " (3645,),\n",
       " (3660,),\n",
       " (3760,),\n",
       " (3767,),\n",
       " (3771,),\n",
       " (3784,),\n",
       " (3805,),\n",
       " (3819,),\n",
       " (3824,),\n",
       " (3863,),\n",
       " (3870,),\n",
       " (3881,),\n",
       " (3884,),\n",
       " (3957,),\n",
       " (3959,),\n",
       " (3991,),\n",
       " (4052,),\n",
       " (4058,),\n",
       " (4186,),\n",
       " (4209,),\n",
       " (4280,),\n",
       " (4300,),\n",
       " (4305,),\n",
       " (4308,),\n",
       " (4377,),\n",
       " (4380,),\n",
       " (4388,),\n",
       " (4393,),\n",
       " (4396,),\n",
       " (4410,),\n",
       " (4415,),\n",
       " (4430,),\n",
       " (4436,),\n",
       " (4439,),\n",
       " (4441,),\n",
       " (4443,),\n",
       " (4459,),\n",
       " (4466,),\n",
       " (4486,),\n",
       " (4493,),\n",
       " (4496,),\n",
       " (4512,),\n",
       " (4518,),\n",
       " (4523,),\n",
       " (4526,),\n",
       " (4539,),\n",
       " (4542,),\n",
       " (4545,),\n",
       " (4549,),\n",
       " (4553,),\n",
       " (4558,),\n",
       " (4561,),\n",
       " (4564,),\n",
       " (4571,),\n",
       " (4573,),\n",
       " (4575,),\n",
       " (4578,),\n",
       " (4583,),\n",
       " (4591,),\n",
       " (4922,),\n",
       " (4936,),\n",
       " (4945,),\n",
       " (4965,),\n",
       " (4987,),\n",
       " (5007,),\n",
       " (5028,),\n",
       " (5057,),\n",
       " (5077,),\n",
       " (5109,),\n",
       " (5121,),\n",
       " (5137,),\n",
       " (5197,),\n",
       " (5214,),\n",
       " (5234,),\n",
       " (5256,),\n",
       " (5276,),\n",
       " (5293,),\n",
       " (5314,),\n",
       " (5377,),\n",
       " (5427,),\n",
       " (5441,),\n",
       " (5472,),\n",
       " (5504,),\n",
       " (5521,),\n",
       " (5522,),\n",
       " (5543,),\n",
       " (5568,),\n",
       " (5589,),\n",
       " (5648,),\n",
       " (5669,),\n",
       " (5714,),\n",
       " (5723,),\n",
       " (5745,),\n",
       " (5854,),\n",
       " (5866,),\n",
       " (5953,),\n",
       " (6146,),\n",
       " (6205,),\n",
       " (6218,),\n",
       " (6279,),\n",
       " (6308,),\n",
       " (6332,),\n",
       " (6359,),\n",
       " (6444,),\n",
       " (6562,),\n",
       " (6604,),\n",
       " (6619,),\n",
       " (6634,),\n",
       " (6653,),\n",
       " (6685,),\n",
       " (6777,),\n",
       " (6791,),\n",
       " (6800,),\n",
       " (6810,),\n",
       " (6818,),\n",
       " (6828,),\n",
       " (6833,),\n",
       " (6843,),\n",
       " (6856,),\n",
       " (6866,),\n",
       " (6877,),\n",
       " (6890,),\n",
       " (6898,),\n",
       " (6910,),\n",
       " (6921,),\n",
       " (6936,),\n",
       " (6950,),\n",
       " (6956,),\n",
       " (6967,),\n",
       " (6976,),\n",
       " (6984,),\n",
       " (6995,),\n",
       " (7016,),\n",
       " (7149,),\n",
       " (7164,),\n",
       " (7167,),\n",
       " (7195,),\n",
       " (7589,),\n",
       " (7677,),\n",
       " (7705,),\n",
       " (7987,),\n",
       " (8000,),\n",
       " (8045,),\n",
       " (8059,),\n",
       " (8072,),\n",
       " (8191,),\n",
       " (8215,),\n",
       " (8303,),\n",
       " (8306,),\n",
       " (8616,),\n",
       " (8624,),\n",
       " (8628,),\n",
       " (8631,),\n",
       " (8632,),\n",
       " (8644,),\n",
       " (8707,),\n",
       " (8711,),\n",
       " (8761,),\n",
       " (8766,),\n",
       " (8767,),\n",
       " (8786,),\n",
       " (8788,),\n",
       " (8812,),\n",
       " (8840,),\n",
       " (8842,),\n",
       " (8860,),\n",
       " (8870,),\n",
       " (8873,),\n",
       " (8879,),\n",
       " (8889,),\n",
       " (8920,),\n",
       " (8929,),\n",
       " (8933,),\n",
       " (8985,),\n",
       " (9019,),\n",
       " (9025,),\n",
       " (9033,),\n",
       " (9098,),\n",
       " (9109,),\n",
       " (9224,),\n",
       " (9231,),\n",
       " (9285,),\n",
       " (9295,),\n",
       " (9338,),\n",
       " (9384,),\n",
       " (9704,),\n",
       " (9741,),\n",
       " (9746,),\n",
       " (9753,),\n",
       " (9837,),\n",
       " (9839,),\n",
       " (9873,),\n",
       " (9900,),\n",
       " (9932,),\n",
       " (9936,),\n",
       " (9952,),\n",
       " (9956,),\n",
       " (9960,),\n",
       " (9962,),\n",
       " (9967,),\n",
       " (10054,),\n",
       " (10204,),\n",
       " (10348,),\n",
       " (10411,),\n",
       " (10420,),\n",
       " (10611,),\n",
       " (10761,),\n",
       " (10784,),\n",
       " (10918,),\n",
       " (10927,),\n",
       " (11011,),\n",
       " (11048,),\n",
       " (11080,),\n",
       " (11091,),\n",
       " (11113,),\n",
       " (11117,),\n",
       " (11216,),\n",
       " (11219,),\n",
       " (11222,),\n",
       " (11228,),\n",
       " (11234,),\n",
       " (11239,),\n",
       " (11254,),\n",
       " (11301,),\n",
       " (11314,),\n",
       " (11461,),\n",
       " (11708,),\n",
       " (12499,),\n",
       " (12564,),\n",
       " (12826,),\n",
       " (13055,),\n",
       " (13069,),\n",
       " (13078,),\n",
       " (13150,),\n",
       " (13173,),\n",
       " (13177,),\n",
       " (13195,),\n",
       " (13210,),\n",
       " (13234,),\n",
       " (13238,),\n",
       " (13240,),\n",
       " (13246,),\n",
       " (13252,),\n",
       " (13255,),\n",
       " (13280,),\n",
       " (13311,),\n",
       " (13357,),\n",
       " (13366,),\n",
       " (13419,),\n",
       " (13436,),\n",
       " (13458,),\n",
       " (13463,),\n",
       " (13534,),\n",
       " (13593,),\n",
       " (13602,),\n",
       " (13631,),\n",
       " (13649,),\n",
       " (13662,),\n",
       " (13667,),\n",
       " (13713,),\n",
       " (13721,),\n",
       " (13723,),\n",
       " (13765,),\n",
       " (13790,),\n",
       " (13848,),\n",
       " (13849,),\n",
       " (13864,),\n",
       " (13925,),\n",
       " (13943,),\n",
       " (13954,),\n",
       " (13962,),\n",
       " (13969,),\n",
       " (14006,),\n",
       " (14024,),\n",
       " (14037,),\n",
       " (14059,),\n",
       " (14201,),\n",
       " (14220,),\n",
       " (14244,),\n",
       " (14256,),\n",
       " (14276,),\n",
       " (14427,),\n",
       " (14550,),\n",
       " (14582,),\n",
       " (14600,),\n",
       " (14679,),\n",
       " (14726,),\n",
       " (14810,),\n",
       " (14832,),\n",
       " (14850,),\n",
       " (14855,),\n",
       " (14868,),\n",
       " (14889,),\n",
       " (14910,),\n",
       " (14923,),\n",
       " (14932,),\n",
       " (14943,),\n",
       " (15371,),\n",
       " (15434,),\n",
       " (15450,),\n",
       " (15475,),\n",
       " (15832,),\n",
       " (15882,),\n",
       " (15910,),\n",
       " (15945,),\n",
       " (15978,),\n",
       " (16012,),\n",
       " (16015,),\n",
       " (16063,),\n",
       " (16119,),\n",
       " (16124,),\n",
       " (16176,),\n",
       " (16185,),\n",
       " (16206,),\n",
       " (16215,),\n",
       " (16222,),\n",
       " (16264,),\n",
       " (16280,),\n",
       " (16289,),\n",
       " (16358,),\n",
       " (17239,),\n",
       " (17488,),\n",
       " (17506,),\n",
       " (17530,),\n",
       " (17547,),\n",
       " (17614,),\n",
       " (17618,),\n",
       " (17627,),\n",
       " (17629,),\n",
       " (17632,),\n",
       " (17634,),\n",
       " (17636,),\n",
       " (17699,),\n",
       " (17806,),\n",
       " (18038,),\n",
       " (18167,),\n",
       " (18191,),\n",
       " (18284,),\n",
       " (18287,),\n",
       " (18627,),\n",
       " (18655,),\n",
       " (18663,),\n",
       " (18674,),\n",
       " (18678,),\n",
       " (18681,),\n",
       " (18694,),\n",
       " (18746,),\n",
       " (18753,),\n",
       " (18772,),\n",
       " (18788,),\n",
       " (18911,),\n",
       " (18923,),\n",
       " (18936,),\n",
       " (18942,),\n",
       " (18977,),\n",
       " (18989,),\n",
       " (19001,),\n",
       " (19006,),\n",
       " (19013,),\n",
       " (19023,),\n",
       " (19032,),\n",
       " (19046,),\n",
       " (19092,),\n",
       " (19107,),\n",
       " (19112,),\n",
       " (19154,),\n",
       " (19169,),\n",
       " (19198,),\n",
       " (19203,),\n",
       " (19207,),\n",
       " (19229,),\n",
       " (19244,),\n",
       " (19253,),\n",
       " (19267,),\n",
       " (19341,),\n",
       " (19350,),\n",
       " (19379,),\n",
       " (19383,),\n",
       " (19391,),\n",
       " (19459,),\n",
       " (19483,),\n",
       " (19565,),\n",
       " (19591,),\n",
       " (19622,),\n",
       " (19664,),\n",
       " (19667,),\n",
       " (19708,),\n",
       " (19711,),\n",
       " (19717,),\n",
       " (19740,),\n",
       " (19750,),\n",
       " (19765,),\n",
       " (19778,),\n",
       " (19792,),\n",
       " (19798,),\n",
       " (19812,),\n",
       " (19814,),\n",
       " (19833,),\n",
       " (19842,),\n",
       " (19847,),\n",
       " (19861,),\n",
       " (19868,),\n",
       " (19888,),\n",
       " (19914,),\n",
       " (19940,),\n",
       " (19969,),\n",
       " (20002,),\n",
       " (20004,),\n",
       " (20028,),\n",
       " (20032,),\n",
       " (20046,),\n",
       " (20049,),\n",
       " (20065,),\n",
       " (20096,),\n",
       " (20116,),\n",
       " (20122,),\n",
       " (20139,),\n",
       " (20178,),\n",
       " (20399,),\n",
       " (20406,),\n",
       " (20562,),\n",
       " (20583,),\n",
       " (20644,),\n",
       " (20658,),\n",
       " (20678,),\n",
       " (20790,),\n",
       " (21020,),\n",
       " (21196,),\n",
       " (21281,),\n",
       " (21412,),\n",
       " (21447,),\n",
       " (21481,),\n",
       " (21484,),\n",
       " (21503,),\n",
       " (21515,),\n",
       " (21581,),\n",
       " (21592,),\n",
       " (21600,),\n",
       " (21634,),\n",
       " (21641,),\n",
       " (21665,),\n",
       " (21690,),\n",
       " (21700,),\n",
       " (21704,),\n",
       " (21722,),\n",
       " (21807,),\n",
       " (21811,),\n",
       " (21826,),\n",
       " (21926,),\n",
       " (21933,),\n",
       " (21937,),\n",
       " (21950,),\n",
       " (21971,),\n",
       " (21985,),\n",
       " (21990,),\n",
       " (22029,),\n",
       " (22036,),\n",
       " (22047,),\n",
       " (22050,),\n",
       " (22123,),\n",
       " (22125,),\n",
       " (22157,),\n",
       " (22218,),\n",
       " (22224,),\n",
       " (22352,),\n",
       " (22375,),\n",
       " (22446,),\n",
       " (22466,),\n",
       " (22471,),\n",
       " (22474,),\n",
       " (22543,),\n",
       " (22546,),\n",
       " (22554,),\n",
       " (22559,),\n",
       " (22562,),\n",
       " (22576,),\n",
       " (22581,),\n",
       " (22596,),\n",
       " (22602,),\n",
       " (22605,),\n",
       " (22607,),\n",
       " (22609,),\n",
       " (22625,),\n",
       " (22632,),\n",
       " (22652,),\n",
       " (22659,),\n",
       " (22662,),\n",
       " (22678,),\n",
       " (22684,),\n",
       " (22689,),\n",
       " (22692,),\n",
       " (22705,),\n",
       " (22708,),\n",
       " (22711,),\n",
       " (22715,),\n",
       " (22719,),\n",
       " (22724,),\n",
       " (22727,),\n",
       " (22730,),\n",
       " (22737,),\n",
       " (22739,),\n",
       " (22741,),\n",
       " (22744,),\n",
       " (22749,),\n",
       " (22757,),\n",
       " (23088,),\n",
       " (23102,),\n",
       " (23111,),\n",
       " (23131,),\n",
       " (23153,),\n",
       " (23173,),\n",
       " (23194,),\n",
       " (23223,),\n",
       " (23243,),\n",
       " (23275,),\n",
       " (23287,),\n",
       " (23303,),\n",
       " (23363,),\n",
       " (23380,),\n",
       " (23400,),\n",
       " (23422,),\n",
       " (23442,),\n",
       " (23459,),\n",
       " (23480,),\n",
       " (23543,),\n",
       " (23593,),\n",
       " (23607,),\n",
       " (23638,),\n",
       " (23670,),\n",
       " (23687,),\n",
       " (23688,),\n",
       " (23709,),\n",
       " (23734,),\n",
       " (23755,),\n",
       " (23814,),\n",
       " (23835,),\n",
       " (23880,),\n",
       " (23889,),\n",
       " (23911,),\n",
       " (24020,),\n",
       " (24032,),\n",
       " (24119,),\n",
       " (24312,),\n",
       " (24371,),\n",
       " (24384,),\n",
       " (24445,),\n",
       " (24474,),\n",
       " (24498,),\n",
       " (24525,),\n",
       " (24610,),\n",
       " (24728,),\n",
       " (24770,),\n",
       " (24785,),\n",
       " (24800,),\n",
       " (24819,),\n",
       " (24851,),\n",
       " (24943,),\n",
       " (24957,),\n",
       " (24966,),\n",
       " (24976,),\n",
       " (24984,),\n",
       " (24994,),\n",
       " (24999,),\n",
       " (25009,),\n",
       " (25022,),\n",
       " (25032,),\n",
       " (25043,),\n",
       " (25056,),\n",
       " (25064,),\n",
       " (25076,),\n",
       " (25087,),\n",
       " (25102,),\n",
       " (25116,),\n",
       " (25122,),\n",
       " (25133,),\n",
       " (25142,),\n",
       " (25150,),\n",
       " (25161,),\n",
       " (25182,),\n",
       " (25315,),\n",
       " (25330,),\n",
       " (25333,),\n",
       " (25361,),\n",
       " (25755,),\n",
       " (25843,),\n",
       " (25871,),\n",
       " (26155,),\n",
       " (26168,),\n",
       " (26213,),\n",
       " (26227,),\n",
       " (26240,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row for row in crawler.conn.execute('select rowid from wordlocation where word_id = 1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Searcher:\n",
    "    def __init__(self, db):\n",
    "        self.conn = sqlite3.connect(db)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.conn.close()\n",
    "    \n",
    "    def commit(self):\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def get_match_rows(self, q):\n",
    "        # Strings to build the query.\n",
    "        fieldlist = 'w0.url_id'\n",
    "        tablelist = ''\n",
    "        clauselist = ''\n",
    "        wordids = []\n",
    "        \n",
    "        # Split the words by spaces.\n",
    "        words = q.split(' ')\n",
    "        tablenumber = 0\n",
    "        \n",
    "        for word in words:\n",
    "            # Get the word id.\n",
    "            c = self.conn.cursor()\n",
    "            wordrow = c.execute('select rowid from wordlist where word=?', (word,)).fetchone()\n",
    "            if wordrow != None:\n",
    "                wordid = wordrow[0]\n",
    "                wordids.append(wordid)\n",
    "                if tablenumber > 0:\n",
    "                    tablelist += ','\n",
    "                    clauselist += ' and '\n",
    "                    clauselist += f'w{tablenumber-1}.url_id=w{tablenumber}.url_id and '\n",
    "                fieldlist += f',w{tablenumber}.location'\n",
    "                tablelist += f'wordlocation w{tablenumber}'\n",
    "                clauselist += f'w{tablenumber}.word_id = {wordid}'\n",
    "                tablenumber += 1\n",
    "        # Create the query from the separate parts.\n",
    "        fullquery = f'select {fieldlist} from {tablelist} where {clauselist}'\n",
    "        print(fullquery)\n",
    "        c = self.conn.cursor()\n",
    "        res = c.execute(fullquery)\n",
    "        rows = [row for row in res]\n",
    "        return rows, wordids\n",
    "    \n",
    "    def get_scored_list(self, rows, word_ids):\n",
    "        total_scores = dict([(row[0], 0) for row in rows])\n",
    "        \n",
    "        # Put the scoring function here.\n",
    "        # weights = []\n",
    "        weights = [(1.0, self.frequency_score(rows)),\n",
    "                   (1.5, self.location_score(rows)),\n",
    "                   (1.0, self.page_rank_score(rows)),\n",
    "                   (1.0, self.link_text_score(rows, word_ids))]\n",
    "        \n",
    "        for (weight, scores) in weights:\n",
    "            for url in total_scores:\n",
    "                total_scores[url] += weight * scores[url]\n",
    "        \n",
    "        return total_scores\n",
    "\n",
    "    def get_url_name(self, id):\n",
    "        return self.conn.cursor().execute('select url from urllist where rowid = ?', (id,)).fetchone()[0]\n",
    "    \n",
    "    def query(self, q):\n",
    "        rows, word_ids = self.get_match_rows(q)\n",
    "        scores = self.get_scored_list(rows, word_ids)\n",
    "        ranked_scores = sorted([(score, url) for (url, score) in scores.items()], reverse=True)\n",
    "        for (score, url_id) in ranked_scores[0:10]:\n",
    "            print(f'{score}\\t{self.get_url_name(url_id)}')\n",
    "    \n",
    "    def normalize_scores(self, scores, small_is_better=False):\n",
    "        \"\"\"\n",
    "        Sometimes a smaller score is better, and vice versa. The normalization\n",
    "        function will take a dictionary of IDs and scores and return a new dictionary with the same IDs,\n",
    "        but with score between 0 and 1. Each score is scaled according to how close it is to the best \n",
    "        result, which will always have a score of 1.\n",
    "        \"\"\"\n",
    "        vsmall = 0.00001 # Avoid division by zero errors.\n",
    "        if small_is_better:\n",
    "            min_score = min(scores.values())\n",
    "            return dict([(u, float(min_score)/max(vsmall,1))\n",
    "                        for (u, l) in scores.items()])\n",
    "        else:\n",
    "            max_score = max(scores.values())\n",
    "            if max_score == 0: max_score = vsmall\n",
    "            return dict([(u, float(c) / max_score) for (u, c) in scores.items()])\n",
    "    \n",
    "    def frequency_score(self, rows):\n",
    "        \"\"\"\n",
    "        The word frequency scores a page based on how many times the words in the query appear on that page.\n",
    "        \"\"\"\n",
    "        counts = dict([(row[0], 0) for row in rows])\n",
    "        \n",
    "        # Create a dictionary with an entry for each unique url id, and count how many times the item appears.\n",
    "        for row in rows: counts[row[0]] += 1\n",
    "            \n",
    "        # Normalize the scores, in this case, bigger is better (occur more frequently).\n",
    "        return self.normalize_scores(counts)\n",
    "\n",
    "    def location_score(self, rows):\n",
    "        \"\"\"\n",
    "        Score the page based on the search term location in the page. \n",
    "        If a page is relevant to the search term, it will appear closer to the top.\n",
    "        The search engine can score results higher if the query term appears early\n",
    "        in the document.\"\"\"\n",
    "        locations = dict([(row[0], 1000000) for row in rows])\n",
    "        for row in rows:\n",
    "            loc = sum(row[1:])\n",
    "            if loc < locations[row[0]]: locations[row[0]] = loc\n",
    "        # The lowest location score (closes to the start) will get a score of 1.\n",
    "        return self.normalize_scores(locations, small_is_better=True)\n",
    "\n",
    "    def distance_score(self, rows):\n",
    "        \"\"\"\n",
    "        When a query contains multiple words, \n",
    "        it is often useful to seek results in which the words in \n",
    "        the query are close to each other in the page.\n",
    "        \"\"\"\n",
    "        # If there are only one word, everyone wins!\n",
    "        if len(rows[0]) <= 2: return dict([(row[0], 1.0) for row in rows])\n",
    "        \n",
    "        # Initialize the dictionary with large values.\n",
    "        min_distance = dict([(row[0], 1000000) for row in rows])\n",
    "        for row in rows:\n",
    "            dist = sum([abs(row[i] - row[i-1])\n",
    "                       for i in range(2, len(row))])\n",
    "            if dist < min_distance[row[0]]: min_distance[row[0]] = dist\n",
    "        # The smaller the distance, means the more similar the results are.\n",
    "        return self.normalize_scores(min_distance, True)\n",
    "\n",
    "    def inbound_link_score(self, rows):\n",
    "        \"\"\"\n",
    "        Count the inbound links on the page and use the total number of links as a metric for the page.\n",
    "        \"\"\"\n",
    "        unique_urls = set([row[0] for row in rows])\n",
    "        inbound_count = dict([(u, self.conn.cursor().execute('select count(*) from link where to_id = ?', (u,)).fetchone()[0]) for u in unique_urls])\n",
    "        return self.normalize_scores(inbound_count)\n",
    "    \n",
    "    def calculate_page_rank(self, iterations=20):\n",
    "        # Clear out the current page rank tables.\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('drop table if exists pagerank')\n",
    "        c.execute('create table pagerank(url_id primary key, score)')\n",
    "        \n",
    "        # Initialize every query with a PageRank of 1.\n",
    "        c.execute('insert into pagerank select rowid, 1.0 from urllist')\n",
    "        self.commit()\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            print(f'iteration {i}')\n",
    "            \n",
    "            for (url_id,) in c.execute('select rowid from urllist'):\n",
    "                pr = 0.15\n",
    "                \n",
    "                # Loop through all the pages that link to this one.\n",
    "                for (linker,) in c.execute(\n",
    "                'select distinct from_id from link where to_id = ?', (url_id,)):\n",
    "                    # Get the page rank of the linker.\n",
    "                    linkingpr = c.execute(\n",
    "                    'select score from pagerank where url_id = ?', (linker,)).fetchone()[0]\n",
    "                    \n",
    "                    # Get the total number of links from the linker.\n",
    "                    linking_count = c.execute(\n",
    "                    'select count(*) from link where from_id = ?', (linker,)).fetchone()[0]\n",
    "                    \n",
    "                    pr + 0.85 * (linkingpr / linking_count)\n",
    "                \n",
    "                c.execute(\n",
    "                'update pagerank set score = ? where url_id = ?', (pr, url_id))\n",
    "            self.commit()\n",
    "    \n",
    "    def page_rank_score(self, rows):\n",
    "        c = self.conn.cursor()\n",
    "        page_ranks = dict([(row[0], c.execute('select score from pagerank where url_id = ?', (row[0],)).fetchone()[0]) for row in rows])\n",
    "        max_rank = max(page_ranks.values())\n",
    "        normalized_scores = dict([(u, float(1)/max_rank) for (u,l) in page_ranks.items()])\n",
    "        return normalized_scores\n",
    "    \n",
    "    def link_text_score(self, rows, word_ids):\n",
    "        \"\"\"\n",
    "        Score the page based on the text of the links to a page to decide how relevant the page is.\n",
    "        \"\"\"\n",
    "        link_scores = dict([(row[0],0) for row in rows])\n",
    "        c = self.conn.cursor()\n",
    "        for word_id in word_ids:\n",
    "            cur = c.execute('select link.from_id, link.to_id from linkwords, link where word_id = ? and linkwords.link_id = link.rowid', (word_id,))\n",
    "            \n",
    "            for (from_id, to_id) in cur:\n",
    "                if to_id in link_scores:\n",
    "                    pr = c.execute(\"\"\"\n",
    "                    select score \n",
    "                    from pagerank \n",
    "                    where url_id = ?\"\"\", (from_id,)).fetchone()[0]\n",
    "                    link_scores[to_id] += pr\n",
    "        max_score = max(link_scores.values())\n",
    "        normalized_scores = dict([(u, float(l)/max_score) for (u,l) in link_scores.items()])\n",
    "        return normalized_scores\n",
    "\n",
    "    # import nn\n",
    "    # net = nn.searchnet(\"nn.db\")\n",
    "#     def nn_score(self, rows, wordids):\n",
    "#         # Get unique url ids as an ordered list.\n",
    "#         urlids = [urlid for urlif in set([row[0] for row in rows])]\n",
    "#         nnres = net.getresult(wordids, urlids)\n",
    "#         scores = dict([(urlids[i], nnres[i]) for i in range(len(urlids))])\n",
    "#         return self.normalize_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select w0.url_id,w0.location,w1.location from wordlocation w0,wordlocation w1 where w0.word_id = 706 and w0.url_id=w1.url_id and w1.word_id = 1\n",
      "4.5\thttps://en.wikipedia.org/wiki/Functional_programming\n",
      "2.882946001367054\thttps://en.wikipedia.org/wiki/Programming_language\n",
      "2.508971291866029\thttps://en.wikipedia.org/w/index.php?title=Functional_programming&action=edit&section=33\n",
      "2.5019224196855774\thttps://web.archive.org/web/20100715042920/http://www.math.grin.edu/~rebelsky/Courses/CS302/99S/Outlines/outline.02.html\n"
     ]
    }
   ],
   "source": [
    "engine = Searcher('searchindex.db')\n",
    "# engine.get_match_rows('functional programming')\n",
    "engine.query('functional programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c782b31e3c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_page_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-3dcd0ed80fbd>\u001b[0m in \u001b[0;36mcalculate_page_rank\u001b[0;34m(self, iterations)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Clear out the current page rank tables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drop table if exists pagerank'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'create table pagerank(url_id primary key, score)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "engine.calculate_page_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[row for row in engine.conn.cursor().execute('select * from wordlist limit 10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Ranking\n",
    "\n",
    "- word frequency: the number of times the words in the query appear in the document can help determine how relevant the document is\n",
    "- document location: the main subject of a document will probably appear near the beginning of the document\n",
    "- word distance: if there are multiple words in the query, they should appear close together in the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
